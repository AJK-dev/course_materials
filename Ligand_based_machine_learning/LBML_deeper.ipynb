{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ageWlWGwW182"
      },
      "source": [
        "# Fingerprinting EGFR ligands for machine learning\n",
        "\n",
        "**Note:** this exercise is based on T7 from [TeachOpenCADD](https://doi.org/10.1186/s13321-019-0351-x).\n",
        "\n",
        "Contributors:\n",
        "\n",
        "* Albert J. Kooistra, 2022-2024, [University of Copenhagen](https://drug.ku.dk/staff/?pure=en/persons/612712)\n",
        "* Andrea Volkamer & Talia B. Kimber, 2019-2020, [Volkamer lab](https://volkamerlab.org)\n",
        "* Jacob Gora & Jan Philipp Albrecht, CADD seminar 2018, CharitÃ©/FU Berlin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCzpoTsxW186"
      },
      "source": [
        "## Aim of this practical\n",
        "\n",
        "In this notebook, you will investigate both neural networks as well as random forest to predict the activity of small molecules against a the Epidermal Growth Factor Receptor (EGFR) based on a training set of known active and inactive compounds.\n",
        "\n",
        "This notebook follows the MBC notebook and digs deeper into the machine learning models, cross-validation as well as the different performance measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8octtQWNW187"
      },
      "source": [
        "### Techniques you will use:\n",
        "\n",
        "* Data preparation:\n",
        "    * Fingerprint encoding of small molecules\n",
        "* Supervised Machine learning\n",
        "    * Random forest classifier\n",
        "    * Neural network classifier\n",
        "* Model validation and evaluation\n",
        "    * Validation strategy: K-fold cross-validation\n",
        "    * Performance measures\n",
        "    * Making data splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORyD5MZ8W188"
      },
      "source": [
        "### Data preparation: Molecule encoding\n",
        "\n",
        "As discussed in the lecture, computers do not understand chemistry by themselves. Therefore we need to convert the molecules into a representation that can be used as features for learning. The most commonly used representation of small molecules are the so-called molecular fingerprints.\n",
        "\n",
        "Here we will use two common different fingerprinting techniques:\n",
        "\n",
        "* **MACCS**:\n",
        "\n",
        "* **Morgan fingerprints**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXxA7eaNW19A"
      },
      "source": [
        "## Practical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let us start setting up the environment\n",
        "\n",
        "First, we will setup our python environment by installing all the libraries that we need to process all data, generate the fingerprints and to create our machine learning models.\n",
        "\n",
        "Note that some of the cells in this notebook are \"hidden\" by default, click on *View* at the top then click on *Expand Sections* to show all cells. For slower computers, this might be a bit too much but you can also hide the cells again by clicking on *Collapse sections*."
      ],
      "metadata": {
        "id": "HMcsPJBpYov1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi -qqq"
      ],
      "metadata": {
        "id": "OSlnV9hYXjb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwyfpSzW19B"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from warnings import filterwarnings\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm, metrics, clone\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import auc, accuracy_score, recall_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit.Chem.AllChem import GetMorganFingerprint, GetMorganFingerprintAsBitVect\n",
        "\n",
        "# Silence some expected warnings\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "# Fix seed for reproducible results\n",
        "SEED = 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQcAN9KzW19C"
      },
      "outputs": [],
      "source": [
        "# Set path to this notebook and create data folder\n",
        "HERE = Path(_dh[-1])\n",
        "DATA = HERE / \"data\"\n",
        "!mkdir \"data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEU8lDeW19D"
      },
      "source": [
        "### Load compound and activity data\n",
        "\n",
        "Let's start by loading our data, which focuses on the Epidermal growth factor receptor (EGFR) kinase. The *csv* file from a repository is loaded into a dataframe with the important columns:\n",
        "\n",
        "* CHEMBL-ID\n",
        "* SMILES string of the corresponding compound\n",
        "* Measured affinity: pIC50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZMMR_ZJW19D"
      },
      "outputs": [],
      "source": [
        "# Read EGFR inhibitor data\n",
        "chembl_df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/AJK-dev/course_materials/main/Ligand_based_machine_learning/data/EGFR_compounds_lipinski.csv\",\n",
        "    index_col=0,\n",
        ")\n",
        "\n",
        "# Look at head\n",
        "print(\"Shape of dataframe : \", chembl_df.shape)\n",
        "chembl_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkBBJ5DFW19F"
      },
      "outputs": [],
      "source": [
        "# Keep only the columns we want\n",
        "chembl_df = chembl_df[[\"molecule_chembl_id\", \"smiles\", \"pIC50\"]]\n",
        "chembl_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Why would we only keep these columns? Is more data not always better?"
      ],
      "metadata": {
        "id": "v_JerKmDaEKc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jN6-sR_W19G"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUvTCKw5W19G"
      },
      "source": [
        "#### Data labeling\n",
        "We need to classify each compound as active or inactive. Therefore, we use the pIC50 value.\n",
        "\n",
        "* pIC50 = -log10(IC50)\n",
        "* IC50 describes the amount of substance needed to inhibit, _in vitro_, a process by 50% .\n",
        "* The pIC50 value we use to split the data differs from target to target and also depends on the data availability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qXGTpG6W19H"
      },
      "outputs": [],
      "source": [
        "# Add column for classification of Active versus Inactive\n",
        "chembl_df[\"active\"] = 0\n",
        "\n",
        "# Mark every molecule as active with an pIC50 of CUTOFF , 0 otherwise\n",
        "chembl_df.loc[chembl_df[chembl_df.pIC50 >= 6.3].index, \"active\"] = 1.0\n",
        "\n",
        "print(\"Number of active compounds:\", int(chembl_df.active.sum()))\n",
        "print(\"Number of inactive compounds:\", len(chembl_df) - int(chembl_df.active.sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACTION:** Plot the distribution of the pIC50 datapoints below. Use the pandas plot function to plot the density as a linegraph or a histogram in the code box below. See https://pandas.pydata.org/docs/user_guide/visualization.html\n",
        "\n",
        "\n",
        "**ACTION:** Based on the graph and common sense, define the value for CUTOFF above to make a split between active and inactive in your dataset. Feel free to improve on the simplistic code above.\n",
        "\n",
        "**Question:** What are the limitations and dangers of splitting a dataset in such a way? What are potential pitfalls?"
      ],
      "metadata": {
        "id": "fmID0PZnafKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: plot the distribution of pIC50 values for the compounds to get an insight in the distribution of the values\n",
        "\n",
        "# Use the plot function of pandas itself\n"
      ],
      "metadata": {
        "id": "-f2SvwOTGE5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoqZkh9QW19I"
      },
      "source": [
        "#### Molecule encoding\n",
        "\n",
        "Now we define a function `smiles_to_fp` to generate fingerprints from SMILES.\n",
        "For now, we incorporated the choice between the following fingerprints:\n",
        "\n",
        "* maccs\n",
        "* morgan2 and morgan3 + 4 additional variants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVc-L6_SW19I"
      },
      "outputs": [],
      "source": [
        "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
        "    \"\"\"\n",
        "    Encode a molecule from a SMILES string into a fingerprint.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles : str\n",
        "        The SMILES string defining the molecule.\n",
        "\n",
        "    method : str\n",
        "        The type of fingerprint to use. Default is MACCS keys.\n",
        "\n",
        "    n_bits : int\n",
        "        The length of the fingerprint.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        The fingerprint array.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # convert smiles to RDKit mol object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    if method == \"maccs\":\n",
        "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
        "    elif method == \"morgan2\":\n",
        "        return np.array(GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits))\n",
        "    elif method == \"morgan3\":\n",
        "        return np.array(GetMorganFingerprintAsBitVect(mol, 3, nBits=n_bits))\n",
        "    elif method == \"feat_morgan2\":\n",
        "        return np.array(GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits, useFeatures = True))\n",
        "    elif method == \"feat_morgan3\":\n",
        "        return np.array(GetMorganFingerprintAsBitVect(mol, 3, nBits=n_bits, useFeatures = True))\n",
        "    elif method == \"count_morgan2\":\n",
        "        return np.array(GetMorganFingerprint(mol, 2, nBits=n_bits, useCounts=True))\n",
        "    elif method == \"count_morgan3\":\n",
        "        return np.array(GetMorganFingerprint(mol, 3, nBits=n_bits, useCounts=True))\n",
        "    else:\n",
        "        print(f\"Warning: Wrong method specified: {method}. Default will be used instead.\")\n",
        "        return np.array(MACCSkeys.GenMACCSKeys(mol))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUYQPhYEW19J"
      },
      "outputs": [],
      "source": [
        "compound_df = chembl_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wixrUs7sW19J"
      },
      "outputs": [],
      "source": [
        "# Add column for fingerprint\n",
        "compound_df[\"fp\"] = compound_df[\"smiles\"].apply(smiles_to_fp)\n",
        "compound_df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Why are we using the bit-vector morgan fingerprint two times in our function? What is the difference between *morgan2* and *morgan3* (see slides)?\n",
        "\n",
        "**Question:** There are two times two other morgan variants, what does the useFeatures option change for the feat_morgan variants? Is this a good or a bad idea?\n",
        "\n",
        "**Question:** When we applied the fingerprint function above, we did not specify a specific fingerprint. Which fingerprint is now present in our *compound_df* variable?"
      ],
      "metadata": {
        "id": "2wSZQGbab6rT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10d68za6W18-"
      },
      "source": [
        "### Model validation and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rKng33FW18_"
      },
      "source": [
        "#### Performance measures\n",
        "\n",
        "* **Sensitivity**, also true positive rate\n",
        "    * TPR = TP/(FN + TP)\n",
        "    * _Intuitively_: Out of all actual positives, how many were predicted as positive?\n",
        "* **Specificity**, also true negative rate\n",
        "    * TNR = TN/(FP + TN)\n",
        "    * _Intuitively_: Out of all actual negatives, how many were predicted as negative?\n",
        "* **Accuracy**, also the trueness\n",
        "    * ACC = (TP + TN)/(TP + TN + FP + FN)\n",
        "    * _Intuitively_: Proportion of correct predictions.\n",
        "* **ROC-curve**, receiver operating characteristic curve\n",
        "    * A graphical plot that illustrates the diagnostic ability of our classifier\n",
        "    * Plots the sensitivity against the specificity\n",
        "* **AUC**, the area under the ROC curve (AUC):  \n",
        "    * Describes the probability that a classifier will rank a randomly chosen positive instance higher than a negative one\n",
        "    * Values between 0 and 1, the higher the better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9bWe7hxW19A"
      },
      "source": [
        "| What the model predicts  | True active  |  True inactive |\n",
        "|---|---|---|\n",
        "| active  |  True Positive (TP) |  False Positive (FP) |\n",
        "| inactive  |  False Negative (FN) |  True Negative (TN) |"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Why are there so many metrics? Couldn't we, for example, simply use the *Sensitivity* and skip the rest?"
      ],
      "metadata": {
        "id": "jqh3vDv7bLul"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMmbb0uPW19K"
      },
      "source": [
        "### Machine Learning (ML)\n",
        "\n",
        "In the following, we will try several ML approaches to classify our molecules. We will use:\n",
        "\n",
        "* Random Forest (RF)\n",
        "* Artificial Neural Network (ANN)\n",
        "* OPTIONAL: Support Vector Machine (SVM)\n",
        "\n",
        "Additionally, we will comment on the results.\n",
        "\n",
        "The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as overfitting and to assess the generalization ability of the model.\n",
        "\n",
        "We start by defining a function `model_training_and_validation` which fits a model on a random train-test split of the data and returns measures such as accuracy, sensitivity, specificity and AUC evaluated on the test set. We also plot the ROC curves using `plot_roc_curves_for_models`.\n",
        "\n",
        "We then define a function named `crossvalidation` which executes a cross validation procedure and prints the statistics of the results over the folds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKuFUqwWW19K"
      },
      "source": [
        "#### Helper functions\n",
        "Helper function to plot customized ROC curves. Code inspired by [stackoverflow](https://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWznfw3kW19K"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curves_for_models(models, test_x, test_y, save_png=False):\n",
        "    \"\"\"\n",
        "    Helper function to plot customized roc curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models: dict\n",
        "        Dictionary of pretrained machine learning models.\n",
        "    test_x: list\n",
        "        Molecular fingerprints for test set.\n",
        "    test_y: list\n",
        "        Associated activity labels for test set.\n",
        "    save_png: bool\n",
        "        Save image to disk (default = False)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig:\n",
        "        Figure.\n",
        "    \"\"\"\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Below for loop iterates through your models list\n",
        "    for model in models:\n",
        "        # Select the model\n",
        "        ml_model = model[\"model\"]\n",
        "        # Prediction probability on test set\n",
        "        test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
        "        # Prediction class on test set\n",
        "        test_pred = ml_model.predict(test_x)\n",
        "        # Compute False postive rate and True positive rate\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(test_y, test_prob)\n",
        "        # Calculate Area under the curve to display on the plot\n",
        "        auc = roc_auc_score(test_y, test_prob)\n",
        "        # Plot the computed values\n",
        "        ax.plot(fpr, tpr, label=(f\"{model['label']} AUC area = {auc:.2f}\"))\n",
        "\n",
        "    # Custom settings for the plot\n",
        "    ax.plot([0, 1], [0, 1], \"r--\")\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(\"Receiver Operating Characteristic\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    # Save plot\n",
        "    if save_png:\n",
        "        fig.savefig(f\"{DATA}/roc_auc\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIVbsWe1W19L"
      },
      "source": [
        "Helper function to calculate model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga7evLL-W19L"
      },
      "outputs": [],
      "source": [
        "def model_performance(ml_model, test_x, test_y, verbose=True):\n",
        "    \"\"\"\n",
        "    Helper function to calculate model performance\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    test_x: list\n",
        "        Molecular fingerprints for test set.\n",
        "    test_y: list\n",
        "        Associated activity labels for test set.\n",
        "    verbose: bool\n",
        "        Print performance measure (default = True)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        Accuracy, sensitivity, specificity, auc on test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prediction probability on test set\n",
        "    test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
        "\n",
        "    # Prediction class on test set\n",
        "    test_pred = ml_model.predict(test_x)\n",
        "\n",
        "    # Performance of model on test set\n",
        "    accuracy = accuracy_score(test_y, test_pred)\n",
        "    sens = recall_score(test_y, test_pred)\n",
        "    spec = recall_score(test_y, test_pred, pos_label=0)\n",
        "    auc = roc_auc_score(test_y, test_prob)\n",
        "\n",
        "    if verbose:\n",
        "        # Print performance results\n",
        "        print(f\"Accuracy: {accuracy:.2}\")\n",
        "        print(f\"Sensitivity: {sens:.2f}\")\n",
        "        print(f\"Specificity: {spec:.2f}\")\n",
        "        print(f\"AUC: {auc:.2f}\")\n",
        "\n",
        "    return accuracy, sens, spec, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z9TGyrMW19M"
      },
      "source": [
        " Helper function to fit a machine learning model on a random train-test split of the data and return the performance measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFf5muROW19N"
      },
      "outputs": [],
      "source": [
        "def model_training_and_validation(ml_model, name, splits, verbose=True):\n",
        "    \"\"\"\n",
        "    Fit a machine learning model on a random train-test split of the data\n",
        "    and return the performance measures.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    name: str\n",
        "        Name of machine learning algorithm: RF, SVM, ANN\n",
        "    splits: list\n",
        "        List of desciptor and label data: train_x, test_x, train_y, test_y.\n",
        "    verbose: bool\n",
        "        Print performance info (default = True)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        Accuracy, sensitivity, specificity, auc on test set.\n",
        "\n",
        "    \"\"\"\n",
        "    train_x, test_x, train_y, test_y = splits\n",
        "\n",
        "    # Fit the model\n",
        "    ml_model.fit(train_x, train_y)\n",
        "\n",
        "    # Calculate model performance results\n",
        "    accuracy, sens, spec, auc = model_performance(ml_model, test_x, test_y, verbose)\n",
        "\n",
        "    return accuracy, sens, spec, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRtDgY_qW19N"
      },
      "source": [
        "**Preprocessing**: Split the data (will be reused for the other models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfiC0KdfW19O"
      },
      "outputs": [],
      "source": [
        "fingerprint_to_model = compound_df.fp.tolist()\n",
        "label_to_model = compound_df.active.tolist()\n",
        "\n",
        "# Split data randomly in train and test set\n",
        "# note that we use test/train_x for the respective fingerprint splits\n",
        "# and test/train_y for the respective label splits\n",
        "(\n",
        "    static_train_x,\n",
        "    static_test_x,\n",
        "    static_train_y,\n",
        "    static_test_y,\n",
        ") = train_test_split(fingerprint_to_model, label_to_model, test_size=0.2, random_state=np.random.RandomState(SEED))\n",
        "splits = [static_train_x, static_test_x, static_train_y, static_test_y]\n",
        "print(\"Training data size:\", len(static_train_x))\n",
        "print(\"Test data size:\", len(static_test_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqMXKhdXW19P"
      },
      "source": [
        "#### Random forest classifier\n",
        "\n",
        "We start with a random forest classifier, where we first set the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wguybg1VW19Q"
      },
      "source": [
        "We train the model on a random train-test split and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgpSV6HbW19Q"
      },
      "outputs": [],
      "source": [
        "# Set model parameter for random forest\n",
        "param = {\n",
        "    \"random_state\": np.random.RandomState(SEED),\n",
        "    \"n_estimators\": DECISION_TREES,  # number of trees to grows\n",
        "    \"criterion\": \"entropy\",  # cost function to be optimized for a split\n",
        "}\n",
        "model_RF = RandomForestClassifier(**param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i88r2CfiW19Q"
      },
      "outputs": [],
      "source": [
        "# Fit model on single split\n",
        "performance_measures = model_training_and_validation(model_RF, \"RF\", splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAJOR OBJECTIVE 1**\n",
        "\n",
        "Above we are creating a random forest model and train it, but we have to specify what number of trees to use (DECISION_TREES) - try different numbers and evaluate what works well for our current dataset. Note that the more trees, the longer this process will take (recommended max of 1000)\n",
        "\n",
        "The number of trees are a big, but obvious parameters for a random forest model. However, there are many other ways to change the behaviour of a random forest. Go through the documentation of the RandomForest and check out the different parameters that you can change.\n",
        "\n",
        "* Select three parameters\n",
        "* Explain what the parameters entail and how it impacts the random forest\n",
        "* Perform a grid-search in the code cells below to find the optimal parameters. That is: test different variants of all 3 parameters x all other 3 parameters and compare the performance of each of the models.\n",
        "\n",
        "\n",
        "FINALLY, store the best performing model as model_RF in the *models* array. If you have multiple interesting models you want to compare later on, store them as model_RF1, model_RF2 etc."
      ],
      "metadata": {
        "id": "7B32J3XtObrc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAOBhCSjOdSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qOFcZQ9gOdIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbKZ-sKpOcva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JgiF38CW19R"
      },
      "outputs": [],
      "source": [
        "# Initialize the list that stores all models. First one is RF.\n",
        "models = [{\"label\": \"Model_RF\", \"model\": model_RF}]\n",
        "# Plot roc curve\n",
        "plot_roc_curves_for_models(models, static_test_x, static_test_y);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4ji3wgmW19T"
      },
      "source": [
        "#### Neural network classifier\n",
        "The last approach we try here is a neural network model. We train an MLPClassifier (Multi-layer Perceptron classifier) with X layers, each with NUM_NEURONS neurons. As before, we do the crossvalidation procedure and plot the results. For more information on MLP, see [sklearn MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iePaqDXcQvi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fbgCckuMW19T"
      },
      "outputs": [],
      "source": [
        "# Specify model\n",
        "model_ANN = MLPClassifier(hidden_layer_sizes=(NUM_NEURONS_LAYER1, NUM_NEURONS_LAYER2), random_state=np.random.RandomState(SEED))\n",
        "\n",
        "# Fit model on single split\n",
        "performance_measures = model_training_and_validation(model_ANN, \"ANN\", splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAJOR OBJECTIVE 2**\n",
        "\n",
        "As a next step we are create our neural network models. Evaluate a few different setups for number of layers and number of neurons. The more neurons and the more layers, the longer the training will take (use a max of 3 layers and a max of 10 neurons per layer).\n",
        "\n",
        "During the lecture, we discussed a few crucial aspects of neural networks that you will vary here and evaluate the impact.\n",
        "See the MLPClassifier documentation for more information: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "* Vary the activation function\n",
        "* Vary the absolute learning rate using the constant learning rate\n",
        "* Vary the number of epochs that the model is trained for\n",
        "\n",
        "Perform another grid-search in the code cells below to find the optimal parameters. That is: test different variants of all 3 parameters x all other 3 parameters and compare the performance of each of the models.\n",
        "\n",
        "\n",
        "\n",
        "FINALLY, similar to the random forest models store the best performing model as model_ANN in the *models* array. If you have multiple interesting models you want to compare later on, store them as model_ANN1, model_ANN2 etc.\n",
        "!Note: keep track of which parameters you used to which model!\n"
      ],
      "metadata": {
        "id": "bczEWMD4e5gW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlaMNAGNOC-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ByYlvcKwOC8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1t5lthbrOC5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hF7F4Q1XOC2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMwcrbLlOCy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZ26VIWmOCrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmS9YvYnOCix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XM1gEG_aOCP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUlGJNSWW19U"
      },
      "outputs": [],
      "source": [
        "# Append ANN model\n",
        "models.append({\"label\": \"Model_ANN\", \"model\": model_ANN})\n",
        "# Plot roc curve\n",
        "plot_roc_curves_for_models(models, static_test_x, static_test_y, True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kTDUdr6W19U"
      },
      "source": [
        "Your models should show good values for all measured values (see AUCs) and thus seem to be predictive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E2I_APOW19R"
      },
      "source": [
        "#### OPTIONAL - Support vector classifier\n",
        "Here we train a SVM with a radial-basis function kernel (also: squared-exponential kernel).\n",
        "For more information, see [sklearn RBF kernel](http://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "i4u90DvOW19R"
      },
      "outputs": [],
      "source": [
        "# Specify model\n",
        "model_SVM = svm.SVC(kernel=\"rbf\", C=1, gamma=0.1, probability=True)\n",
        "\n",
        "# Fit model on single split\n",
        "performance_measures = model_training_and_validation(model_SVM, \"SVM\", splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "nbsphinx-thumbnail"
        ],
        "id": "mCX1jKy6W19S"
      },
      "outputs": [],
      "source": [
        "# Append SVM model\n",
        "models.append({\"label\": \"Model_SVM\", \"model\": model_SVM})\n",
        "# Plot roc curve\n",
        "plot_roc_curves_for_models(models, static_test_x, static_test_y);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question & ACTION:** In the function above, we set the function that SVM uses for the kernel \"trick\" to RBF.\n",
        "Evaluate the performance for, for example, a *linear* or a *poly* (polynomial) or *sigmoid* kernel."
      ],
      "metadata": {
        "id": "D8jp6F1VeRy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changing your input features - Major objective 3!"
      ],
      "metadata": {
        "id": "kGG_9G-HxDNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go back in the code (or better: make a copy and edit the code in the cells below) and test different fingerprints for your best neural network and random forest models.\n",
        "Try different fingerprints, try different fingerprint lengths, try counts versus bits and compare the outcome."
      ],
      "metadata": {
        "id": "0Rfu0mrEweGl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljw2sJU2xNe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3aDq1puxNXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3acYawT-xNMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwHh5lXdW19U"
      },
      "source": [
        "#### Improving our validation with folds: cross-validation\n",
        "\n",
        "Next, we will perform cross-validation experiments with the three different models.\n",
        "Therefore, we define a helper function for machine learning model training and validation in a cross-validation loop."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**: Why do we need cross-validation again?\n",
        "\n",
        "**Question**: What is the downside of using very little (e.g. 2) or a lot of folds (e.g. 100)?"
      ],
      "metadata": {
        "id": "OkrZwW6ZgTXd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aita1vUJW18_"
      },
      "source": [
        "#### Validation strategy: k-fold cross validation\n",
        "\n",
        "* This model validation technique splits the dataset in *k* parts/folds in an iterative manner:\n",
        "    * Training data set: *k-1* folds are considered as the known dataset on which the model is trained\n",
        "    * Test dataset: The unknown fold is used to validate the model\n",
        "    * Process is repeated for each of the folds\n",
        "* The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as over-fitting and to assess the generalization ability of the model.\n",
        "\n",
        "![K-fold cross validation overview](https://github.com/AJK-dev/course_materials/blob/main/Ligand_based_machine_learning/images/kfold_validation.png?raw=1)\n",
        "\n",
        "_Figure 2_: Schematic depiction of k-fold cross validation. Figure by [Knowledge Transfer](https://androidkt.com)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9llfEBpW19U"
      },
      "outputs": [],
      "source": [
        "def crossvalidation(ml_model, df, n_folds=5, verbose=False):\n",
        "    \"\"\"\n",
        "    Machine learning model training and validation in a cross-validation loop.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    df: pd.DataFrame\n",
        "        Data set with SMILES and their associated activity labels.\n",
        "    n_folds: int, optional\n",
        "        Number of folds for cross-validation.\n",
        "    verbose: bool, optional\n",
        "        Performance measures are printed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "\n",
        "    \"\"\"\n",
        "    t0 = time.time()\n",
        "    # Shuffle the indices for the k-fold cross-validation\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=np.random.RandomState(SEED))\n",
        "\n",
        "    # Results for each of the cross-validation folds\n",
        "    acc_per_fold = []\n",
        "    sens_per_fold = []\n",
        "    spec_per_fold = []\n",
        "    auc_per_fold = []\n",
        "\n",
        "    # Loop over the folds\n",
        "    for train_index, test_index in kf.split(df):\n",
        "        # clone model -- we want a fresh copy per fold!\n",
        "        fold_model = clone(ml_model)\n",
        "        # Training\n",
        "\n",
        "        # Convert the fingerprint and the label to a list\n",
        "        train_x = df.iloc[train_index].fp.tolist()\n",
        "        train_y = df.iloc[train_index].active.tolist()\n",
        "\n",
        "        # Fit the model\n",
        "        fold_model.fit(train_x, train_y)\n",
        "\n",
        "        # Testing\n",
        "\n",
        "        # Convert the fingerprint and the label to a list\n",
        "        test_x = df.iloc[test_index].fp.tolist()\n",
        "        test_y = df.iloc[test_index].active.tolist()\n",
        "\n",
        "        # Performance for each fold\n",
        "        accuracy, sens, spec, auc = model_performance(fold_model, test_x, test_y, verbose)\n",
        "\n",
        "        # Save results\n",
        "        acc_per_fold.append(accuracy)\n",
        "        sens_per_fold.append(sens)\n",
        "        spec_per_fold.append(spec)\n",
        "        auc_per_fold.append(auc)\n",
        "\n",
        "    # Print statistics of results\n",
        "    print(\n",
        "        f\"Mean accuracy: {np.mean(acc_per_fold):.2f} \\t\"\n",
        "        f\"and std : {np.std(acc_per_fold):.2f} \\n\"\n",
        "        f\"Mean sensitivity: {np.mean(sens_per_fold):.2f} \\t\"\n",
        "        f\"and std : {np.std(sens_per_fold):.2f} \\n\"\n",
        "        f\"Mean specificity: {np.mean(spec_per_fold):.2f} \\t\"\n",
        "        f\"and std : {np.std(spec_per_fold):.2f} \\n\"\n",
        "        f\"Mean AUC: {np.mean(auc_per_fold):.2f} \\t\"\n",
        "        f\"and std : {np.std(auc_per_fold):.2f} \\n\"\n",
        "        f\"Time taken : {time.time() - t0:.2f}s\\n\"\n",
        "    )\n",
        "\n",
        "    return acc_per_fold, sens_per_fold, spec_per_fold, auc_per_fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXr--WJBW19V"
      },
      "source": [
        "**Cross-validation**\n",
        "\n",
        "We now apply cross-validation and show the statistics for all three ML models. In real world conditions, cross-validation usually applies 5 or more folds, but for the sake of performance we will reduce it to 3. You can change the value of `N_FOLDS` in this cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKOimaIsW19W"
      },
      "outputs": [],
      "source": [
        "N_FOLDS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tta00I9AW19W"
      },
      "source": [
        "_Note_: Next cell takes long to execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVWx6rhKW19W"
      },
      "outputs": [],
      "source": [
        "for model in models:\n",
        "    print(\"\\n======= \")\n",
        "    print(f\"{model['label']}\")\n",
        "    crossvalidation(model[\"model\"], compound_df, n_folds=N_FOLDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_xeAWIKW19W"
      },
      "source": [
        "We look at the cross-validation performance for molecules encoded using Morgan fingerprint and not MACCS keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCmqogTZW19X"
      },
      "outputs": [],
      "source": [
        "# Reset data frame\n",
        "compound_df = chembl_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l9_TOdSW19X"
      },
      "outputs": [],
      "source": [
        "# Adjust FINGERPRINT to use morgan with a radius of 3 instead of the current fingerprint.\n",
        "compound_df[\"fp\"] = compound_df[\"smiles\"].apply(smiles_to_fp, args=(FINGERPRINT,))\n",
        "compound_df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERYMjxbfW19X"
      },
      "source": [
        "_Note_: Next cell takes long to execute\n",
        "\n",
        "**Question**: Why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQzX9ghlW19X"
      },
      "outputs": [],
      "source": [
        "for model in models:\n",
        "    print(\"\\n=======\")\n",
        "    print(model[\"label\"])\n",
        "    crossvalidation(model[\"model\"], compound_df, n_folds=N_FOLDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Now look back and summarize the steps you've taken in creating and evaluating your models, starting at the input collection. Are you happy with the results? Are there elements that are missing?  \n"
      ],
      "metadata": {
        "id": "bdnUliCaifNZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiB5iL8yW19Y"
      },
      "source": [
        "# DONE!\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "toc-autonumbering": true,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}