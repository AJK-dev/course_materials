{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ageWlWGwW182"
      },
      "source": [
        "# Screening for EGFR ligands using machine learning\n",
        "\n",
        "**Note:** this exercise is based on T7 from [TeachOpenCADD](https://doi.org/10.1186/s13321-019-0351-x).\n",
        "\n",
        "Contributors:\n",
        "\n",
        "* Albert J. Kooistra, 2022, [University of Copenhagen](https://drug.ku.dk/staff/?pure=en/persons/612712)\n",
        "* Andrea Volkamer & Talia B. Kimber, 2019-2020, [Volkamer lab](https://volkamerlab.org)\n",
        "* Jacob Gora & Jan Philipp Albrecht, CADD seminar 2018, Charité/FU Berlin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCzpoTsxW186"
      },
      "source": [
        "## Aim of this practical\n",
        "\n",
        "Machine learning (ML) has gained quite a momentum in drug discovery and especially in ligand-based virtual screening / predictive modeling. In this tutorial, you will learn how to use different supervised ML algorithms to predict the activity of novel compounds against a protein target of interest (EGFR) based on a training set of known active and inactive compounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8octtQWNW187"
      },
      "source": [
        "### Techniques you will use:\n",
        "\n",
        "* Data preparation:\n",
        "    * Loading and checking input data\n",
        "    * Splitting the dataset into active and inactive molecules\n",
        "    * Encoding the structure of small molecules into fingerprints\n",
        "* Supervised Machine learning\n",
        "    * Random forest\n",
        "    * Artificial neural network\n",
        "    * Training ML models\n",
        "* Model validation and evaluation\n",
        "    * Evaluating ML models\n",
        "    * Performance measures\n",
        "    * ROC plots\n",
        "* Prediction of new molecules: applying the trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXxA7eaNW19A"
      },
      "source": [
        "## Practical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before we get started\n",
        "\n",
        "Note that some of the boxes (i.e. cells) in this notebook are \"hidden\" by default, you can simply click on the gray bar to view them. You can also click on *View* at the top then click on *Expand Sections* to show all cells. For some computers this might be a bit too much, but you can always hide the cells again by clicking on *View* => *Collapse sections*.\n",
        "\n"
      ],
      "metadata": {
        "id": "HMcsPJBpYov1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the environment\n",
        "\n",
        "First, we will setup our coding environment by installing existing packages/libraries that we need to process the molecular and small molecule data, generate the fingerprints and to create our machine learning models. Simply execute/play the (hidden) code cells below to get started, this might take a few minutes.\n"
      ],
      "metadata": {
        "id": "JR3k0JCOAAGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi -qqq\n",
        "!pip install mols2grid -qqq"
      ],
      "metadata": {
        "id": "OSlnV9hYXjb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwyfpSzW19B"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from warnings import filterwarnings\n",
        "from IPython.display import Javascript\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mols2grid\n",
        "from sklearn import svm, metrics, clone\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import auc, accuracy_score, recall_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
        "\n",
        "# Silence some expected warnings\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "# Fix seed for reproducible results\n",
        "SEED = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQcAN9KzW19C"
      },
      "outputs": [],
      "source": [
        "# Set path to this notebook and create data folder\n",
        "HERE = Path(_dh[-1])\n",
        "DATA = HERE / \"data\"\n",
        "!mkdir \"data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEU8lDeW19D"
      },
      "source": [
        "## Data acquisition\n",
        "\n",
        "###Loading our compound and activity data\n",
        "\n",
        "Let's start by loading our data, which is a set of compounds that have been experimentally tested for their affinity on the **Epidermal growth factor receptor** (EGFR). The *csv* file from a repository is loaded into a dataframe with the important columns:\n",
        "\n",
        "* CHEMBL-ID\n",
        "* SMILES string of the corresponding compound\n",
        "* Measured affinity: pIC50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZMMR_ZJW19D"
      },
      "outputs": [],
      "source": [
        "# Read EGFR inhibitor data\n",
        "chembl_df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/AJK-dev/course_materials/main/Ligand_based_machine_learning/data/EGFR_compounds_lipinski.csv\",\n",
        "    index_col=0,\n",
        ")\n",
        "\n",
        "# Let's take a look at first few data rows\n",
        "print(\"Shape of dataframe : \", chembl_df.shape)\n",
        "chembl_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkBBJ5DFW19F"
      },
      "outputs": [],
      "source": [
        "# Keep only the columns we want\n",
        "chembl_df = chembl_df[[\"molecule_chembl_id\", \"smiles\", \"pIC50\"]]\n",
        "chembl_df.head()\n",
        "\n",
        "# Let's round all pIC50 values to one demical\n",
        "chembl_df = chembl_df.round({'pIC50': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:** \n",
        "\n",
        "*   What protein family does EGFR belong to (DISCUSS: what is its function)?\n",
        "*   What is the endogenous small molecule ligand (not substrate) of EGFR?\n",
        "*   Name one FDA-approved drug for EGFR and its therapeutic function\n",
        "*   How many molecules do we have in our dataset?\n",
        "*   DISCUSS: Why would we only keep these columns? Is more data not always better?\n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   Verify you have completed all questions in Absalon before continuing\n",
        "*   If you are completely ready, check the checkbox and continue."
      ],
      "metadata": {
        "id": "v_JerKmDaEKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_data = False #@param {type:\"boolean\"}\n",
        "if not done_data:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FI4u_Z8fb8_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a peak at a few of those ligands with a high activity"
      ],
      "metadata": {
        "id": "OEMohDzz1SAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mols2grid.display(chembl_df.head(15), smiles_col=\"smiles\")"
      ],
      "metadata": {
        "id": "Bl8zWUfl1XNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also look at a few of the ligands that have very low/no affinity for the EGFR kinase"
      ],
      "metadata": {
        "id": "o3mhh8S8XWER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mols2grid.display(chembl_df.tail(15), smiles_col=\"smiles\")"
      ],
      "metadata": {
        "id": "PHjk620pXdmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:** \n",
        "* DISCUSS: Can you already see some sort of a pattern in the molecules with a high affinity?\n",
        "* DISCUSS: What about the low/no affinity molecules, are they lacking this pattern?\n",
        "* Which group of the endogenous ligand of EGFR looks a bit similar?\n",
        "NOTE: the machine learning models will try to identify such patterns in a similar way.\n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   Verify you have completed all questions in Absalon before continuing\n",
        "*   If you are completely ready, check the checkbox and continue."
      ],
      "metadata": {
        "id": "CNTV3XUB2SUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_molecules = False #@param {type:\"boolean\"}\n",
        "if not done_molecules:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "id": "R_fTT_mfXFXe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jN6-sR_W19G"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUvTCKw5W19G"
      },
      "source": [
        "#### Data labeling\n",
        "We need to classify each compound as active or inactive. Therefore, we use the pIC50 value.\n",
        "\n",
        "* IC50 describes the concentration of the compound needed to inhibit a process (_in vitro_) by 50%.\n",
        "* pIC50 = -log10(IC50)\n",
        "* Note that the IC50 needs to be specified in **molar concentration**\n",
        "* The pIC50 value we use to split the data differs from target to target and also depends on the data availability.\n",
        "\n",
        "🛑 Specify the pIC50 equivalent of IC50 = 500 nM in the input box below up to a single decimal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qXGTpG6W19H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# Mark every molecule as 1 (active) with an IC50 <= 500 nM, otherwise inactive (0)\n",
        "activity_cutoff = None #@param {type:\"number\"}\n",
        "if activity_cutoff == None:\n",
        "  display(Javascript(\"element.innerHTML = '<span style=\\\"color: red\\\"><b>ERROR:</b> check the specified activity cutoff</span>';\"))\n",
        "elif round(10**(7-1*activity_cutoff)) != 5:\n",
        "    display(Javascript(\"element.innerHTML = '<span style=\\\"color: red\\\"><b>ERROR:</b> check the specified activity cutoff</span>';\"))\n",
        "    print(\"The value you provided corresponds to an IC50 of\", round(10**(7-1*activity_cutoff)*100), \"nM\")\n",
        "else:\n",
        "  # Add column for activity\n",
        "  chembl_df[\"active\"] = 0\n",
        "\n",
        "  # Define the compounds that meet the specified cutoff as \"active\" (1.0)\n",
        "  chembl_df.loc[chembl_df[chembl_df.pIC50 >= activity_cutoff].index, \"active\"] = 1.0\n",
        "\n",
        "  print(\"Number of active compounds:\", int(chembl_df.active.sum()))\n",
        "  print(\"Number of inactive compounds:\", len(chembl_df) - int(chembl_df.active.sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What are the limitations/potential pitfalls of defining active and inactive molecules in this way?\n",
        "**DISCUSS:** Is the resulting number of active and number of inactive molecules balanced? Is this important?"
      ],
      "metadata": {
        "id": "fmID0PZnafKz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoqZkh9QW19I"
      },
      "source": [
        "#### Molecule encoding\n",
        "\n",
        "Now we define a function `smiles_to_fp` to generate fingerprints from SMILES.\n",
        "For now, we will only use the simple dictionary based fingerpint called MACCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVc-L6_SW19I"
      },
      "outputs": [],
      "source": [
        "def smiles_to_fp(smiles):\n",
        "    # Take the smiles and convert it to a molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Calculate the MACCS fingerprint using the molecule object\n",
        "    return np.array(MACCSkeys.GenMACCSKeys(mol))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wixrUs7sW19J"
      },
      "outputs": [],
      "source": [
        "# Make a copy of our dataset\n",
        "compound_df = chembl_df.copy()\n",
        "\n",
        "# Calculating the fingerprint and storing it in a new column called \"FP\"\n",
        "compound_df[\"fp\"] = compound_df[\"smiles\"].apply(smiles_to_fp)\n",
        "compound_df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Read [this blog post](https://drzinph.com/computing-molecular-descriptors-intro/) to get a better understanding of what molecular fingerprints are. Also review the presentation slides before answering the questions below and continuing.\n",
        "\n",
        "* What is MACCS for type of fingerprints and what does MACCS stand for?\n",
        "\n",
        "* Click on the \"magic wand\" in the top right corner of the table. You will now see a lot of zeros and ones in the \"fp\" column. How many bits does a MACCS fingerprint contain for each compound and what do these 0s and 1s represent?\n",
        "  * Tip: the number of bits in the MACCS fingerprint is predefined and thus the same for each compound.\n",
        "  * Note: in the table each compound has one more bit than usual, but this is because the first 0 is ignored.\n",
        "\n",
        "--\n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   Verify you have completed all questions in Absalon before continuing\n",
        "*   If you are completely ready, check the checkbox and continue."
      ],
      "metadata": {
        "id": "rp76A6TKQe14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_fingerprints = False #@param {type:\"boolean\"}\n",
        "if not done_fingerprints:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "v-ngmRFJP687"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4KqcBvW188"
      },
      "source": [
        "## Machine learning theory\n",
        "\n",
        "To successfully apply ML, we need a large data set of molecules, a molecular encoding, a label per molecule in the data set, and a ML algorithm to train a model. Then, we can make predictions for new molecules.\n",
        "\n",
        "![ML overview](https://github.com/AJK-dev/course_materials/blob/main/Ligand_based_machine_learning/images/ML_overview.png?raw=1)\n",
        "\n",
        "_Figure 1_: Machine learning overview: Molecular encoding, label, ML algorithm, prediction. Figure by Andrea Volkamer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQcxMV3ZW189"
      },
      "source": [
        "### Machine learning (ML)\n",
        "\n",
        "There are different types of machine learning algorithms (text adapted from [scikit-learn page](http://scikit-learn.org/stable/)), the most popular being:\n",
        "\n",
        "* Regression (supervised): Prediction of a continuous-values attribute associated with an object\n",
        "* Classification (supervised): Identify which category an object belongs to\n",
        "* Clustering (unsupervised): Automated grouping of similar objects into sets\n",
        "* Dimensionality reduction (unsupervised): Reducing the number of random variables to consider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMmbb0uPW19K"
      },
      "source": [
        "### Machine Learning (ML) algorithms\n",
        "\n",
        "Now we have arrived at the magic part 🧙‍♂️ of this exercise: building the machine learning models. As you heard in the lectures, there are a lot of different ML methods available. In the following, we will try out two very different ML approaches to build a good activity predictor for our molecules. \n",
        "\n",
        "We will use:\n",
        "* **Artificial neural networks (ANNs)**: An ANN is based on a collection of connected units or nodes called artificial neurons which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. The output neurons indicate the probability that a molecule is either active or inactive.\n",
        "* **Random Forest (RF)**: Ensemble of decision trees. A single decision tree splits the features of the input vector - in our case the bits of the fingerprints - in a way that maximizes an correct predictions. In the random forest algorithm a lot of different discision trees are generated, however these trees are de-correlated because the choice of features - the bits of the fingerprints - that a tree can use, are chosen randomly for each tree. The output of the random forest is a based on the prediction from all the trees (majority voting), i.e. the output with the most votes wins.\n",
        "\n",
        "#![Voting](https://miro.medium.com/max/764/0*F4HiydKf6wBHBI5F)\n",
        "\n",
        "_Figure 2_: Example of a random forest and majority voting. Figure taken from [KDnuggets](https://www.kdnuggets.com/2020/01/random-forest-powerful-ensemble-learning-algorithm.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:** \n",
        "* In our case, we will try to predict wether a molecule has an affinity for EGFR or not. What is this type of machine learning called?\n",
        "* Why can different trees in a random forest predict a different outcome?\n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   Verify you have completed all questions in Absalon before continuing\n",
        "*   If you are completely ready, check the checkbox and continue."
      ],
      "metadata": {
        "id": "RIYjLY0ZkQvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_ml_theory = False #@param {type:\"boolean\"}\n",
        "if not done_ml_theory:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JyuSPB1XkQW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10d68za6W18-"
      },
      "source": [
        "## Machine learning - training, validation and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rKng33FW18_"
      },
      "source": [
        "#### Performance measures\n",
        "\n",
        "| What the model predicts  | True active  |  True inactive |\n",
        "|---|---|---|\n",
        "| active  |  True Positive (TP) |  False Positive (FP) |\n",
        "| inactive  |  False Negative (FN) |  True Negative (TN) |\n",
        "\n",
        "* **Sensitivity**, also true positive rate (TPR)\n",
        "    * TPR = TP/(FN + TP) \n",
        "    * _Intuitively_: Out of all actual positives, how many were predicted as positive?\n",
        "* **Specificity**, also true negative rate (TNR)\n",
        "    * TNR = TN/(FP + TN)\n",
        "    * _Intuitively_: Out of all actual negatives, how many were predicted as negative?\n",
        "* **Accuracy**, also the trueness\n",
        "    * ACC = (TP + TN)/(TP + TN + FP + FN)\n",
        "    * _Intuitively_: Proportion of correct predictions.\n",
        "\n",
        "--\n",
        "\n",
        "* **ROC-curve**, receiver operating characteristic curve\n",
        "    * A graphical plot that illustrates the diagnostic ability of our classifier\n",
        "    * Plots the sensitivity (Y-axis) against 1 - specificity (X-axis)\n",
        "* **AUC**, the area under the ROC curve (AUC):  \n",
        "    * Describes the probability that a classifier will rank a randomly chosen positive instance higher than a negative one\n",
        "    * Values between 0 and 1, the higher the better"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSS:** why are there so many metrics? Couldn't we, for example, simply use the *Sensitivity* and skip the rest?\n"
      ],
      "metadata": {
        "id": "cRSo4_Cv41Hs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKuFUqwWW19K"
      },
      "source": [
        "#### Helper functions\n",
        "The code in the cells below are Helper functions to evaluate the performance of our machine learning method. You can just execute the cells below.\n",
        "\n",
        "Code inspired by [stackoverflow](https://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWznfw3kW19K"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curves_for_models(models, test_x, test_y, save_png=False):\n",
        "    \"\"\"\n",
        "    Helper function to plot customized roc curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models: dict\n",
        "        Dictionary of pretrained machine learning models.\n",
        "    test_x: list\n",
        "        Molecular fingerprints for test set.\n",
        "    test_y: list\n",
        "        Associated activity labels for test set.\n",
        "    save_png: bool\n",
        "        Save image to disk (default = False)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig:\n",
        "        Figure.\n",
        "    \"\"\"\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_dpi(150)\n",
        "\n",
        "    # Below for loop iterates through your models list\n",
        "    for model in models:\n",
        "        # Select the model\n",
        "        ml_model = model[\"model\"]\n",
        "        # Prediction probability on test set\n",
        "        test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
        "        # Prediction class on test set\n",
        "        test_pred = ml_model.predict(test_x)\n",
        "        # Compute False postive rate and True positive rate\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(test_y, test_prob)\n",
        "        # Calculate Area under the curve to display on the plot\n",
        "        auc = roc_auc_score(test_y, test_prob)\n",
        "        # Plot the computed values\n",
        "        ax.plot(fpr, tpr, label=(f\"{model['label']} AUC = {auc:.2f}\"))\n",
        "\n",
        "    # Custom settings for the plot\n",
        "    ax.plot([0, 1], [0, 1], \"r--\")\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(\"Receiver Operating Characteristic\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    # Save plot\n",
        "    if save_png:\n",
        "        fig.savefig(f\"{DATA}/roc_auc\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIVbsWe1W19L"
      },
      "source": [
        "Helper function to calculate model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga7evLL-W19L"
      },
      "outputs": [],
      "source": [
        "def model_performance(ml_model, test_x, test_y, verbose=True):\n",
        "    \"\"\"\n",
        "    Helper function to calculate model performance\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    test_x: list\n",
        "        Molecular fingerprints for test set.\n",
        "    test_y: list\n",
        "        Associated activity labels for test set.\n",
        "    verbose: bool\n",
        "        Print performance measure (default = True)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        Accuracy, sensitivity, specificity, auc on test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prediction probability on test set\n",
        "    test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
        "\n",
        "    # Prediction class on test set\n",
        "    test_pred = ml_model.predict(test_x)\n",
        "\n",
        "    # Performance of model on test set\n",
        "    accuracy = accuracy_score(test_y, test_pred)\n",
        "    sens = recall_score(test_y, test_pred)\n",
        "    spec = recall_score(test_y, test_pred, pos_label=0)\n",
        "    auc = roc_auc_score(test_y, test_prob)\n",
        "\n",
        "    if verbose:\n",
        "        # Print performance results\n",
        "        print(f\"Accuracy: {accuracy:.2}\")\n",
        "        print(f\"Sensitivity: {sens:.2f}\")\n",
        "        print(f\"Specificity: {spec:.2f}\")\n",
        "        print(f\"AUC: {auc:.2f}\")\n",
        "\n",
        "    return accuracy, sens, spec, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z9TGyrMW19M"
      },
      "source": [
        " Helper function to fit a machine learning model on a random train-test split of the data and return the performance measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFf5muROW19N"
      },
      "outputs": [],
      "source": [
        "def model_training_and_validation(ml_model, name, splits, verbose=True):\n",
        "    \"\"\"\n",
        "    Fit a machine learning model on a random train-test split of the data\n",
        "    and return the performance measures.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    name: str\n",
        "        Name of machine learning algorithm: RF, SVM, ANN\n",
        "    splits: list\n",
        "        List of desciptor and label data: train_x, test_x, train_y, test_y.\n",
        "    verbose: bool\n",
        "        Print performance info (default = True)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        Accuracy, sensitivity, specificity, auc on test set.\n",
        "\n",
        "    \"\"\"\n",
        "    train_x, test_x, train_y, test_y = splits\n",
        "\n",
        "    # Fit the model\n",
        "    ml_model.fit(train_x, train_y)\n",
        "\n",
        "    # Calculate model performance results\n",
        "    accuracy, sens, spec, auc = model_performance(ml_model, test_x, test_y, verbose)\n",
        "\n",
        "    return accuracy, sens, spec, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRtDgY_qW19N"
      },
      "source": [
        "**Preprocessing**: Split the data (will be reused for the other models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfiC0KdfW19O"
      },
      "outputs": [],
      "source": [
        "fingerprint_to_model = compound_df.fp.tolist()\n",
        "label_to_model = compound_df.active.tolist()\n",
        "\n",
        "# Split data randomly in train and test set\n",
        "# note that we use test/train_x for the respective fingerprint splits\n",
        "# and test/train_y for the respective label splits\n",
        "(\n",
        "    static_train_x,\n",
        "    static_test_x,\n",
        "    static_train_y,\n",
        "    static_test_y,\n",
        ") = train_test_split(fingerprint_to_model, label_to_model, test_size=0.2, random_state=np.random.RandomState(SEED))\n",
        "splits = [static_train_x, static_test_x, static_train_y, static_test_y]\n",
        "print(\"Training data size:\", len(static_train_x))\n",
        "print(\"Test data size:\", len(static_test_x))\n",
        "\n",
        "# Clean start before machine learning\n",
        "rf_models = []\n",
        "nn_models = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqMXKhdXW19P"
      },
      "source": [
        "#### Random forest classifier\n",
        "\n",
        "We start with a random forest model, where we first set the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wguybg1VW19Q"
      },
      "source": [
        "We train the model on a random train-test split and plot the evaluation results.\n",
        "\n",
        "**NOTE:** the value displayed next to the slider isn't always updated correctly, check the code to see if the correct value has been selected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgpSV6HbW19Q"
      },
      "outputs": [],
      "source": [
        "number_of_trees = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "# Set model parameter for random forest\n",
        "param = {\n",
        "    \"random_state\": np.random.RandomState(SEED),  # fixed random seed for reproducibility\n",
        "    \"n_estimators\": number_of_trees,  # number of trees to grows\n",
        "    \"criterion\": \"entropy\",  # cost function to be optimized for a split\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i88r2CfiW19Q"
      },
      "outputs": [],
      "source": [
        "# Build the model based on single split\n",
        "print(\"Building new random forest model using\", number_of_trees, \"decision trees\")\n",
        "model_RF = RandomForestClassifier(**param)\n",
        "performance_measures = model_training_and_validation(model_RF, \"RF\", splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JgiF38CW19R"
      },
      "outputs": [],
      "source": [
        "# Store our RF model in a list\n",
        "model_name = \"RF_\" + str(number_of_trees) + \"_trees\"\n",
        "\n",
        "# Check existing models\n",
        "index_list = {x[\"label\"] : i for i, x in enumerate(rf_models)}\n",
        "\n",
        "# Add new model to list\n",
        "if model_name in index_list:\n",
        "  rf_models[index_list[model_name]][\"model\"] = model_RF\n",
        "else:\n",
        "  rf_models.append({\"label\": model_name, \"model\": model_RF})\n",
        "\n",
        "# Plot the results of the ROC curve\n",
        "plot_roc_curves_for_models(rf_models, static_test_x, static_test_y);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** \n",
        "* Build a model using several different number of trees in the random forest. Compare the performance of the model using 1 tree, 5 trees, 10 trees, and a 100 trees. Which performs best with regard to sensitivity and ROC?\n",
        "* Is the performance of the models using 10 trees and 100 trees the same?\n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   Verify you have completed all questions in Absalon before continuing\n",
        "*   If you are completely ready, check the checkbox and continue."
      ],
      "metadata": {
        "id": "-4rB-EwQdP8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_random_forests = False #@param {type:\"boolean\"}\n",
        "if not done_random_forests:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "id": "feXFBqZxn-e_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4ji3wgmW19T"
      },
      "source": [
        "#### Neural network classifier\n",
        "The second and last approach we will use here is an artificial neural network model. We train the neural network with X layers, each with Y neurons. You can specify the layers and number of neurons using the sliders. As before, we do the same validation procedure to check the results and create an ROC plot. \n",
        "\n",
        "For more information on the exact method used (multi-layer perceptron), see [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n",
        "\n",
        "**NOTE:** the value displayed next to the sliders isn't always updated correctly, check the code to see if the correct value has been selected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fbgCckuMW19T"
      },
      "outputs": [],
      "source": [
        "# Specify model\n",
        "number_layers = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "number_neurons = 1 #@param {type:\"slider\", min:1, max:25, step:1}\n",
        "\n",
        "model_ANN = MLPClassifier(hidden_layer_sizes=([number_neurons] * number_layers), random_state=np.random.RandomState(SEED))\n",
        "\n",
        "print(\"Building new neural network using\", number_layers, \"layers and\", number_neurons, \"neurons\")\n",
        "\n",
        "performance_measures = model_training_and_validation(model_ANN, \"ANN\", splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUlGJNSWW19U"
      },
      "outputs": [],
      "source": [
        "# Store our RF model in a list\n",
        "model_name = \"ANN_\" + str(number_layers) + \"_lyrs_\" + str(number_neurons) + \"_nrns\"\n",
        "\n",
        "# Check existing models\n",
        "index_list = {x[\"label\"] : i for i, x in enumerate(nn_models)}\n",
        "\n",
        "# Add new model to list\n",
        "if model_name in index_list:\n",
        "  nn_models[index_list[model_name]][\"model\"] = model_RF\n",
        "else:\n",
        "  # Append ANN model\n",
        "  nn_models.append({\"label\": model_name, \"model\": model_ANN})\n",
        "\n",
        "# Plot roc curve\n",
        "plot_roc_curves_for_models(nn_models, static_test_x, static_test_y, True);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:** \n",
        "* Build a model using several different number of layers and neurons in the neural network. Compare the performance for 1 layer with 1/10/20 neurons and repeat the same for 2 and 4 layers. Based on the AUC, what combination of neurons and layers works best?\n",
        "\n",
        "**DISCUSS:** Once you have found an optimum of layers and neurons, adding more neurons or layers does not significantly impact the prediction anymore. What could be the reason for this?\n",
        "* EXTRA: Visualize the setup of the best neural network here [NN-SVG](http://alexlenail.me/NN-SVG/index.html). Remember to also correctly represent the input layer.\n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   Verify you have completed all questions in Absalon before continuing\n",
        "*   If you are completely ready, check the checkbox and continue."
      ],
      "metadata": {
        "id": "bczEWMD4e5gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_neural_nets = False #@param {type:\"boolean\"}\n",
        "if not done_neural_nets:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "id": "TMJQUvL8xj14",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kTDUdr6W19U"
      },
      "source": [
        "Your models should show relatively high values for all validation measures (see above). What can we carefully conclude from this?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read and discuss the folowing \n",
        "\n",
        "**Questions:** \n",
        "\n",
        "DISCUSS: look back and summarize the steps you've taken in creating and evaluating your models, starting at the input collection. Are you happy with the results? Are there elements that are missing?  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bdnUliCaifNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction 🪄\n",
        "\n",
        "Use your favorite molecular drawer to draw a small molecule. Copy the SMILES and paste it in the input below. Then we will try to predict whether or not, this molecule might have affinity for EGFR!\n",
        "\n",
        "If you don't have molecule sketching software, you can use this online sketcher to draw a molecule [MarvinJS](https://marvinjs-demo.chemaxon.com/latest/). Draw the molecule, then click on the 💾 icon at the top and select SMILES in the dropdown."
      ],
      "metadata": {
        "id": "qr_2Srfo0ru3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_molecule = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if new_molecule == \"\":\n",
        "  print(\"ERROR: Please provide a molecule in the form of a SMILES string\")\n",
        "  sys.exit()"
      ],
      "metadata": {
        "id": "mVb4UAunzUlA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Let's draw our molecule and inspect if it is correct\n",
        "  mols2grid.display([Chem.MolFromSmiles(new_molecule)])"
      ],
      "metadata": {
        "id": "EBgClbLq3yZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will calculate the MACCS fingerprint for this molecule."
      ],
      "metadata": {
        "id": "ninWSzh236Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe for our new molecule\n",
        "newmol_df = pd.DataFrame([[new_molecule]],columns=[\"smiles\"])\n",
        "# Calculate the fingerprint for our new molecule\n",
        "newmol_df[\"fp\"] = newmol_df[\"smiles\"].apply(smiles_to_fp)\n",
        "# Check if everything is ok\n",
        "newmol_df.head()"
      ],
      "metadata": {
        "id": "xa5UGpqb4KW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost there, we are now ready to provide the fingerprint to our trained models and predict the likelyhood of the molecule being an EGFR ligand! \n",
        "So let's apply our models to our new molecule!!"
      ],
      "metadata": {
        "id": "qJHR8-d35iiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = rf_models + nn_models\n",
        "for model in models:\n",
        "    print(\"\\n=======\")\n",
        "    print(\"MODEL:\",model[\"label\"])\n",
        "    prediction = model[\"model\"].predict(newmol_df.fp.to_list())\n",
        "    if prediction:\n",
        "      print(\"Predicted ACTIVE!\")\n",
        "    else:\n",
        "      print(\"Predicted INACTIVE!\")"
      ],
      "metadata": {
        "id": "fjEt4lvb5nng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:** \n",
        "\n",
        "* Find the structure/SMILES of gefitinib/Iressa, an approved EGFR inhibitor, by majority voting do our models agree that this molecule is an EGFR inhbitor? \n",
        "* Find the structure/SMILES of mobocertinib/Exkivity, a recently approved EGFR inhibitor, by majority voting do our models agree that this molecule is an EGFR inhbitor? \n",
        "* Find the structure/SMILES of doxepin/Quitaxon, an antihistamine, by majority voting is this molecule expected to be an EGFR inhbitor? \n",
        "* Find the structure/SMILES of sildenafil/Viagra, a PDE inhibitor, by majority voting is this molecule expected to be an EGFR inhbitor? \n",
        "\n",
        "**🛑 CHECKPOINT**\n",
        "*   ‼️ Complete the full MC-quiz on Absalon ‼️\n",
        "*   If you are completely ready, check the checkbox and continue to the closing discussion."
      ],
      "metadata": {
        "id": "ii6Ye8Wj7Mbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "done_notebook = False #@param {type:\"boolean\"}\n",
        "if not done_notebook:\n",
        "  sys.exit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z0BR0xLkuoQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiB5iL8yW19Y"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "* Which model performed best on our data set and why?\n",
        "    * All three models perform (very) well on our dataset. The best models showed a mean AUC of about 90%. Our neural network showed slightly lower results. \n",
        "    * There might be several reasons why the random forest machine models performed best. Our dataset might be easily separable in active/inactive with some simple tree-like decisions, respectively. Thus, there is not such a complex pattern in the fingerprints to do this classification.\n",
        "    * A cause for the slightly poorer performance of the ANN could be that there was simply too few data to train the model on. ANNs are infamous for their requirement of a lot of data for training.\n",
        "* Was the MACCS fingerprint the right choice?\n",
        "    * Obviously, MACCS was good to start training and validating models to see if a classification is possible. \n",
        "    * However, MACCS keys are rather short (166 bit) compared to others (2048 bit), as for example Morgan fingerprint. As you might expect, having longer fingerprint can help the learning process. \n",
        "\n",
        "\n",
        "### Where can we go from here?\n",
        "\n",
        "* We successfully trained several models. \n",
        "* The next step could be to use these models to do a classification with an unknown screening dataset to predict novel potential EGFR inhibitors.\n",
        "* An example for a large screening data set is e.g. [MolPort](https://www.molport.com/shop/database-download) with over 7 million compounds.\n",
        "* Our models could be used to rank the MolPort compounds and then further study those with the highest predicted probability of being active.\n",
        "* For such an application, see also the [TDT Tutorial](https://github.com/sriniker/TDT-tutorial-2014) developed by S. Riniker and G. Landrum, where they trained a fusion model to screen [eMolecules](https://www.emolecules.com/) for new anti-malaria drugs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJliCe3UW19Y"
      },
      "source": [
        "### References\n",
        "\n",
        "* \"Fingerprints in the RDKit\" [slides](https://www.rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf), G. Landrum, RDKit UGM 2012\n",
        "* Extended-connectivity fingerprints (ECFPs): Rogers, David, and Mathew Hahn. \"Extended-connectivity fingerprints.\" [_Journal of chemical information and modeling_ 50.5 (2010): 742-754.](https://doi.org/10.1021/ci100050t)\n",
        "* Machine learning (ML):\n",
        "  * Random forest (RF): Breiman, L. \"Random Forests\". [_Machine Learning_ **45**, 5–32 (2001).](https://link.springer.com/article/10.1023%2FA%3A1010933404324)\n",
        "  * Support vector machines (SVM): Cortes, C., Vapnik, V. \"Support-vector networks\". [_Machine Learning_ **20**, 273–297 (1995).](https://link.springer.com/article/10.1007%2FBF00994018)\n",
        "  * Artificial neural networks (ANN): Van Gerven, Marcel, and Sander Bohte. \"Artificial neural networks as models of neural information processing.\" [_Frontiers in Computational Neuroscience_ 11 (2017): 114.](https://doi.org/10.3389/fncom.2017.00114)\n",
        "* Performance: \n",
        "  * Sensitivity and specificity ([Wikipedia](https://en.wikipedia.org/wiki/Sensitivity_and_specificity))\n",
        "  * ROC curve and AUC ([Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve))\n",
        "* See also [github notebook by B. Merget](https://github.com/Team-SKI/Publications/tree/master/Profiling_prediction_of_kinase_inhibitors) from [*J. Med. Chem.*, 2017, 60, 474−485](https://pubs.acs.org/doi/10.1021/acs.jmedchem.6b01611) \n",
        "* Activity cutoff $pIC_{50} = 6.3$ (i.e. 500 nM) is used in this practical\n",
        "  * Profiling Prediction of Kinase Inhibitors: Toward the Virtual Assay [<i>J. Med. Chem.</i> (2017), <b>60</b>, 474-485](https://doi.org/10.1021/acs.jmedchem.6b01611)\n",
        "  * Notebook accompanying the publication mentioned before: [Notebook](https://github.com/Team-SKI/Publications/blob/master/Profiling_prediction_of_kinase_inhibitors/Build_ABL1_model.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "toc-autonumbering": true,
    "colab": {
      "name": "Ligand_based_machine_learning.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
